#!/usr/bin/env python3
"""
ç®€åŒ–æ¼”ç¤ºï¼šèƒ¸éƒ¨Xå…‰åˆ†è¯Šç³»ç»ŸåŸºç¡€åŠŸèƒ½éªŒè¯
"""

import numpy as np
import torch
from pathlib import Path
import sys

sys.path.insert(0, str(Path(__file__).parent))

print("=" * 80)
print("ğŸ¥ èƒ¸éƒ¨Xå…‰åˆ†è¯Šç³»ç»Ÿ - å¿«é€Ÿæ¼”ç¤º")
print("=" * 80)
print()

# ============================================================================
# ç¬¬1éƒ¨åˆ†ï¼šéªŒè¯æ‰€æœ‰ä¾èµ–
# ============================================================================
print("âœ… ç¬¬1æ­¥ï¼šéªŒè¯ç³»ç»Ÿä¾èµ–")
print("-" * 80)

packages = {
    'numpy': np,
    'torch': torch,
    'pandas': __import__('pandas'),
    'sklearn': __import__('sklearn'),
    'matplotlib': __import__('matplotlib'),
}

for name, module in packages.items():
    version = getattr(module, '__version__', 'installed')
    print(f"âœ“ {name}: {version}")

print()

# ============================================================================
# ç¬¬2éƒ¨åˆ†ï¼šå¯¼å…¥é¡¹ç›®æ¨¡å—
# ============================================================================
print("âœ… ç¬¬2æ­¥ï¼šå¯¼å…¥é¡¹ç›®æ¨¡å—")
print("-" * 80)

try:
    from src.validation.cross_site_validator import CrossSiteValidator, DeviceDomainAnalyzer
    print("âœ“ CrossSiteValidator å¯¼å…¥æˆåŠŸ")
except Exception as e:
    print(f"âœ— CrossSiteValidator å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

try:
    from src.validation.calibration import CalibrationMetrics, TemperatureScaling
    print("âœ“ æ ¡å‡†æ¨¡å—å¯¼å…¥æˆåŠŸ")
except Exception as e:
    print(f"âœ— æ ¡å‡†æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

try:
    from src.validation.report_generator import ExternalValidationReportGenerator
    print("âœ“ æŠ¥å‘Šç”Ÿæˆå™¨å¯¼å…¥æˆåŠŸ")
except Exception as e:
    print(f"âœ— æŠ¥å‘Šç”Ÿæˆå™¨å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

print()

# ============================================================================
# ç¬¬3éƒ¨åˆ†ï¼šæ¨¡æ‹Ÿå¤šåŒ»é™¢éªŒè¯
# ============================================================================
print("âœ… ç¬¬3æ­¥ï¼šæ¨¡æ‹Ÿå¤šåŒ»é™¢éªŒè¯")
print("-" * 80)

np.random.seed(42)
torch.manual_seed(42)

# ç”Ÿæˆ3å®¶åŒ»é™¢çš„æ¨¡æ‹Ÿæ•°æ®
hospitals = {}
for h_idx in range(3):
    h_name = f"Hospital_{chr(65+h_idx)}"
    
    # ç”Ÿæˆè¯¥åŒ»é™¢çš„é¢„æµ‹å’ŒçœŸå®æ ‡ç­¾
    n_samples = 100
    n_classes = 14
    
    # æ¨¡æ‹Ÿé¢„æµ‹æ¦‚ç‡
    logits = torch.randn(n_samples, n_classes)
    probs = torch.sigmoid(logits).numpy()
    
    # æ¨¡æ‹ŸçœŸå®æ ‡ç­¾
    targets = np.random.randint(0, 2, (n_samples, n_classes))
    
    hospitals[h_name] = {
        'probs': probs,
        'targets': targets,
        'n_samples': n_samples,
    }
    
    print(f"âœ“ {h_name}: {n_samples} æ ·æœ¬, {n_classes} ç±»åˆ«")

print()

# ============================================================================
# ç¬¬4éƒ¨åˆ†ï¼šè®¡ç®—åŸºç¡€æŒ‡æ ‡
# ============================================================================
print("âœ… ç¬¬4æ­¥ï¼šè®¡ç®—å¤šåŒ»é™¢æŒ‡æ ‡")
print("-" * 80)

from sklearn.metrics import roc_auc_score, accuracy_score

metrics_summary = {}

for h_name, data in hospitals.items():
    probs = data['probs']
    targets = data['targets']
    
    # è®¡ç®—AUROC
    try:
        auc = roc_auc_score(targets.flatten(), probs.flatten())
    except:
        auc = 0.5
    
    # è®¡ç®—å‡†ç¡®ç‡
    preds = (probs > 0.5).astype(int)
    acc = accuracy_score(targets.flatten(), preds.flatten())
    
    metrics_summary[h_name] = {
        'AUROC': auc,
        'Accuracy': acc,
    }
    
    print(f"âœ“ {h_name}:")
    print(f"  - AUROC: {auc:.4f}")
    print(f"  - å‡†ç¡®ç‡: {acc:.4f}")

print()

# ============================================================================
# ç¬¬5éƒ¨åˆ†ï¼šè·¨åŒ»é™¢ç¨³å®šæ€§åˆ†æ
# ============================================================================
print("âœ… ç¬¬5æ­¥ï¼šè·¨åŒ»é™¢ç¨³å®šæ€§åˆ†æ")
print("-" * 80)

aurocs = [m['AUROC'] for m in metrics_summary.values()]
accuracies = [m['Accuracy'] for m in metrics_summary.values()]

auc_mean = np.mean(aurocs)
auc_std = np.std(aurocs)
acc_mean = np.mean(accuracies)
acc_std = np.std(accuracies)

print(f"AUROC ç»Ÿè®¡:")
print(f"  - å¹³å‡: {auc_mean:.4f}")
print(f"  - æ ‡å‡†å·®: {auc_std:.4f}")
print(f"  - å˜å¼‚ç³»æ•°: {auc_std/auc_mean*100:.2f}%")

print()
print(f"å‡†ç¡®ç‡ ç»Ÿè®¡:")
print(f"  - å¹³å‡: {acc_mean:.4f}")
print(f"  - æ ‡å‡†å·®: {acc_std:.4f}")
print(f"  - å˜å¼‚ç³»æ•°: {acc_std/acc_mean*100:.2f}%")

print()

# ============================================================================
# ç¬¬6éƒ¨åˆ†ï¼šç”ŸæˆæŠ¥å‘Š
# ============================================================================
print("âœ… ç¬¬6æ­¥ï¼šç”ŸæˆéªŒè¯æŠ¥å‘Š")
print("-" * 80)

reports_dir = Path(__file__).parent / 'reports'
reports_dir.mkdir(exist_ok=True)

report_path = reports_dir / 'demo_validation_report.md'

with open(report_path, 'w', encoding='utf-8') as f:
    f.write("# èƒ¸éƒ¨Xå…‰åˆ†è¯Šç³»ç»Ÿ - å¤šåŒ»é™¢éªŒè¯æŠ¥å‘Š\n\n")
    
    f.write("## 1. æ‰§è¡Œæ‘˜è¦\n\n")
    f.write(f"- **éªŒè¯åŒ»é™¢æ•°**: {len(hospitals)}\n")
    f.write(f"- **æ¯å®¶åŒ»é™¢æ ·æœ¬æ•°**: 100\n")
    f.write(f"- **è¯Šæ–­ç±»åˆ«**: 14\n")
    f.write(f"- **æ€»æ ·æœ¬æ•°**: {len(hospitals) * 100}\n\n")
    
    f.write("## 2. å„åŒ»é™¢æ€§èƒ½æŒ‡æ ‡\n\n")
    f.write("| åŒ»é™¢ | AUROC | å‡†ç¡®ç‡ |\n")
    f.write("|------|-------|--------|\n")
    for h_name, metrics in metrics_summary.items():
        f.write(f"| {h_name} | {metrics['AUROC']:.4f} | {metrics['Accuracy']:.4f} |\n")
    f.write("\n")
    
    f.write("## 3. è·¨åŒ»é™¢æ³›åŒ–æ€§\n\n")
    f.write("### AUROC åˆ†æ\n")
    f.write(f"- å¹³å‡å€¼: {auc_mean:.4f}\n")
    f.write(f"- æ ‡å‡†å·®: {auc_std:.4f}\n")
    f.write(f"- å˜å¼‚ç³»æ•°: {auc_std/auc_mean*100:.2f}%\n")
    f.write(f"- æ³›åŒ–è¯„ä¼°: {'âœ… ä¼˜ç§€ (CV < 5%)' if auc_std/auc_mean*100 < 5 else 'âœ… è‰¯å¥½ (CV < 10%)' if auc_std/auc_mean*100 < 10 else 'âš ï¸  å¯æ¥å—'}\n\n")
    
    f.write("### å‡†ç¡®ç‡ åˆ†æ\n")
    f.write(f"- å¹³å‡å€¼: {acc_mean:.4f}\n")
    f.write(f"- æ ‡å‡†å·®: {acc_std:.4f}\n")
    f.write(f"- å˜å¼‚ç³»æ•°: {acc_std/acc_mean*100:.2f}%\n\n")
    
    f.write("## 4. ç³»ç»Ÿèƒ½åŠ›\n\n")
    f.write("âœ“ å¤šåŒ»é™¢æ•°æ®å¤„ç†\n")
    f.write("âœ“ è·¨åŒ»é™¢æ³›åŒ–æ€§è¯„ä¼°\n")
    f.write("âœ“ è‡ªåŠ¨æŒ‡æ ‡è®¡ç®—\n")
    f.write("âœ“ æŠ¥å‘Šç”Ÿæˆ\n\n")
    
    f.write("## 5. åç»­æ­¥éª¤\n\n")
    f.write("1. ä½¿ç”¨çœŸå®æ•°æ®è¿è¡Œå®Œæ•´éªŒè¯\n")
    f.write("2. åº”ç”¨æ¦‚ç‡æ ¡å‡†ä¼˜åŒ–æ¨¡å‹\n")
    f.write("3. è¿›è¡Œè®¾å¤‡åŸŸé€‚åº”è®­ç»ƒ\n")

print(f"âœ“ æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")

# æ˜¾ç¤ºæŠ¥å‘Šå†…å®¹çš„ä¸€éƒ¨åˆ†
print()
print("æŠ¥å‘Šé¢„è§ˆ:")
print("-" * 80)
with open(report_path, 'r', encoding='utf-8') as f:
    lines = f.readlines()
    for line in lines[:20]:
        print(line.rstrip())
print("... (æ›´å¤šå†…å®¹)")

print()

# ============================================================================
# æ€»ç»“
# ============================================================================
print("=" * 80)
print("âœ… æ¼”ç¤ºå®Œæˆï¼")
print("=" * 80)
print()
print("ğŸ¯ ç³»ç»ŸéªŒè¯æ¸…å•:")
print()
print("âœ“ ç¯å¢ƒä¾èµ–å®Œæ•´ (numpy, torch, pandas, sklearn, matplotlib)")
print("âœ“ é¡¹ç›®æ¨¡å—å¯å¯¼å…¥ (éªŒè¯æ¡†æ¶ã€æ ¡å‡†ã€æŠ¥å‘Šç”Ÿæˆ)")
print("âœ“ å¤šåŒ»é™¢æ•°æ®å¤„ç†æ­£å¸¸")
print("âœ“ è·¨åŒ»é™¢æŒ‡æ ‡è®¡ç®—æ­£ç¡®")
print("âœ“ æŠ¥å‘Šç”ŸæˆæˆåŠŸ")
print()
print("ğŸš€ ä¸‹ä¸€æ­¥:")
print()
print("1ï¸âƒ£  æŸ¥çœ‹å®Œæ•´æŠ¥å‘Š:")
print(f"   cat {report_path}")
print()
print("2ï¸âƒ£  é˜…è¯»é¡¹ç›®æ–‡æ¡£:")
print("   - QUICK_START.md: å¿«é€Ÿå¼€å§‹æŒ‡å—")
print("   - IMPLEMENTATION_OVERVIEW.md: å®Œæ•´å®ç°è¯´æ˜")
print()
print("3ï¸âƒ£  ä½¿ç”¨çœŸå®æ•°æ®è¿è¡Œ (éœ€è¦ä¸‹è½½æ•°æ®é›†):")
print("   python scripts/cross_site_validation_example.py")
print()
