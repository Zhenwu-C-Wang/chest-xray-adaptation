#!/usr/bin/env python3
"""
å¿«é€Ÿç³»ç»ŸéªŒè¯ - ä»…æµ‹è¯•æ¶æ„å’ŒåŸºç¡€åŠŸèƒ½ï¼ˆæ— éœ€PyTorchï¼‰
"""

import os
import sys
from pathlib import Path
import numpy as np
import pandas as pd
from sklearn.metrics import roc_auc_score, accuracy_score, f1_score

print("=" * 70)
print("ğŸš€ èƒ¸éƒ¨Xå…‰åˆ†è¯Šç³»ç»Ÿ - æ¶æ„éªŒè¯")
print("=" * 70)
print()

# æµ‹è¯•1: é¡¹ç›®ç»“æ„
print("âœ… æµ‹è¯•1: é¡¹ç›®ç»“æ„å®Œæ•´æ€§")
print("-" * 70)

base_path = Path(__file__).parent
required_dirs = [
    'data/datasets',
    'src/validation',
    'scripts',
]

all_exist = True
for dir_path in required_dirs:
    full_path = base_path / dir_path
    exists = full_path.exists()
    status = "âœ“" if exists else "âœ—"
    print(f"{status} {dir_path}: {'å­˜åœ¨' if exists else 'ç¼ºå¤±'}")
    if not exists:
        all_exist = False

if all_exist:
    print("\nâœ“ æ‰€æœ‰å¿…éœ€ç›®å½•å­˜åœ¨")
else:
    print("\nâš  æŸäº›ç›®å½•ç¼ºå¤±")

# æµ‹è¯•2: ä»£ç æ–‡ä»¶å®Œæ•´æ€§
print("\nâœ… æµ‹è¯•2: æ ¸å¿ƒä»£ç æ–‡ä»¶")
print("-" * 70)

required_files = [
    'data/datasets/__init__.py',
    'data/datasets/nih_chestxray14.py',
    'data/datasets/chexpert.py',
    'data/datasets/mimic_cxr.py',
    'src/validation/cross_site_validator.py',
    'src/validation/calibration.py',
    'src/validation/report_generator.py',
    'scripts/cross_site_validation_example.py',
]

files_ok = True
for file_path in required_files:
    full_path = base_path / file_path
    exists = full_path.exists()
    if exists:
        size = full_path.stat().st_size
        lines = len(full_path.read_text().splitlines())
        print(f"âœ“ {file_path}")
        print(f"  ({lines} è¡Œ, {size/1024:.1f} KB)")
    else:
        print(f"âœ— {file_path}: ç¼ºå¤±")
        files_ok = False

if files_ok:
    print("\nâœ“ æ‰€æœ‰æ ¸å¿ƒä»£ç æ–‡ä»¶å®Œæ•´")

# æµ‹è¯•3: Pythonè¯­æ³•æ£€æŸ¥
print("\nâœ… æµ‹è¯•3: Pythonè¯­æ³•æ£€æŸ¥")
print("-" * 70)

import py_compile
syntax_ok = True

files_to_check = [
    base_path / 'src/validation/cross_site_validator.py',
    base_path / 'setup_environment.py',
    base_path / 'quick_test.py',
]

for py_file in files_to_check:
    try:
        py_compile.compile(str(py_file), doraise=True)
        print(f"âœ“ {py_file.name}: è¯­æ³•æ­£ç¡®")
    except py_compile.PyCompileError as e:
        print(f"âœ— {py_file.name}: è¯­æ³•é”™è¯¯")
        print(f"  {e}")
        syntax_ok = False

if syntax_ok:
    print("\nâœ“ æ‰€æœ‰æ–‡ä»¶è¯­æ³•æ­£ç¡®")

# æµ‹è¯•4: æ–‡æ¡£å®Œæ•´æ€§
print("\nâœ… æµ‹è¯•4: æ–‡æ¡£å®Œæ•´æ€§")
print("-" * 70)

docs = [
    'QUICK_START.md',
    'IMPLEMENTATION_OVERVIEW.md',
    'VENV_GUIDE.md',
    'SETUP.md',
]

for doc in docs:
    doc_path = base_path / doc
    if doc_path.exists():
        size = doc_path.stat().st_size
        lines = len(doc_path.read_text().splitlines())
        print(f"âœ“ {doc}")
        print(f"  ({lines} è¡Œ, {size/1024:.1f} KB)")
    else:
        print(f"âœ— {doc}: ç¼ºå¤±")

# æµ‹è¯•5: ä¾èµ–æ£€æŸ¥
print("\nâœ… æµ‹è¯•5: Pythonä¾èµ–æ£€æŸ¥")
print("-" * 70)

required_packages = [
    'numpy',
    'pandas',
    'scipy',
    'sklearn',
    'matplotlib',
    'PIL',
    'cv2',
    'yaml',
    'pydantic',
]

import importlib
packages_ok = True
for pkg_name in required_packages:
    # ç‰¹æ®Šæ˜ å°„
    import_name = {
        'sklearn': 'sklearn',
        'PIL': 'PIL',
        'cv2': 'cv2',
        'yaml': 'yaml',
    }.get(pkg_name, pkg_name)
    
    try:
        module = importlib.import_module(import_name)
        version = getattr(module, '__version__', 'unknown')
        print(f"âœ“ {pkg_name}: {version}")
    except ImportError:
        print(f"âœ— {pkg_name}: æœªå®‰è£…")
        packages_ok = False

# æµ‹è¯•6: æ¨¡æ‹Ÿæ•°æ®å¤„ç†ï¼ˆæ— éœ€PyTorchï¼‰
print("\nâœ… æµ‹è¯•6: æ•°æ®å¤„ç†åŠŸèƒ½æµ‹è¯•")
print("-" * 70)

# ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
np.random.seed(42)
n_samples = 100
n_classes = 14

# æ¨¡æ‹Ÿå¤šæ ‡ç­¾åˆ†ç±»çš„æ¦‚ç‡å’Œæ ‡ç­¾
probs = np.random.uniform(0, 1, (n_samples, n_classes))
targets = np.random.randint(0, 2, (n_samples, n_classes))

print(f"âœ“ ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®:")
print(f"  - æ ·æœ¬æ•°: {n_samples}")
print(f"  - ç±»åˆ«æ•°: {n_classes}")

# è®¡ç®—åŸºç¡€æŒ‡æ ‡
overall_auc = roc_auc_score(targets.flatten(), probs.flatten())
binary_preds = (probs > 0.5).astype(int)
accuracy = accuracy_score(targets.flatten(), binary_preds.flatten())

print(f"\nâœ“ è®¡ç®—éªŒè¯æŒ‡æ ‡:")
print(f"  - AUROC: {overall_auc:.4f}")
print(f"  - å‡†ç¡®ç‡: {accuracy:.4f}")

# æŒ‰ç±»åˆ«è®¡ç®—æŒ‡æ ‡
aucs = []
for class_idx in range(n_classes):
    try:
        auc = roc_auc_score(targets[:, class_idx], probs[:, class_idx])
        aucs.append(auc)
    except:
        pass

if aucs:
    print(f"  - å¹³å‡ç±»åˆ«AUROC: {np.mean(aucs):.4f} Â± {np.std(aucs):.4f}")

# æµ‹è¯•7: é…ç½®ç®¡ç†
print("\nâœ… æµ‹è¯•7: é…ç½®æ–‡ä»¶æ£€æŸ¥")
print("-" * 70)

config_files = [
    'requirements.txt',
    'requirements-macos.txt',
    'config.example.json',
    '.gitignore',
]

for config in config_files:
    cfg_path = base_path / config
    if cfg_path.exists():
        size = cfg_path.stat().st_size
        print(f"âœ“ {config} ({size} å­—èŠ‚)")
    else:
        print(f"âš  {config}: å¯é€‰æ–‡ä»¶")

# æ€»ç»“
print("\n" + "=" * 70)
print("âœ… ç³»ç»Ÿæ¶æ„éªŒè¯å®Œæˆï¼")
print("=" * 70)
print()
print("ğŸ“Š ç³»ç»ŸçŠ¶æ€:")
print()
if packages_ok:
    print("âœ“ åŸºç¡€ä¾èµ–æ»¡è¶³ (numpy, pandas, sklearn, matplotlib ç­‰)")
else:
    print("âš  éƒ¨åˆ†ä¾èµ–ç¼ºå¤±")

print()
print("ğŸ“¦ ä¸‹ä¸€æ­¥ - å®‰è£…å®Œæ•´ä¾èµ–:")
print()
print("æ–¹æ¡ˆ 1ï¸âƒ£  ä½¿ç”¨ conda (æ¨èåœ¨macOS):")
print("   conda install pytorch torchvision torchaudio -c pytorch")
print()
print("æ–¹æ¡ˆ 2ï¸âƒ£  ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒ (å¦‚æœç½‘ç»œæ­£å¸¸):")
print("   bash setup_venv.sh")
print()
print("æ–¹æ¡ˆ 3ï¸âƒ£  æ‰‹åŠ¨ä½¿ç”¨ conda ç¯å¢ƒ:")
print("   bash setup_conda.sh")
print()
print("ğŸ’¡ PyTorchå®‰è£…éªŒè¯:")
print("   python -c 'import torch; print(torch.__version__)'")
print()
